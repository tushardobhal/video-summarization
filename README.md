# video-summarization

This project is aimed at Video Captioning (with single sentence) and Dense video Captioning (with multi-sentence paragraph) using only Self-Attention. The video features are extracted using C3D and Two-stream I3D features, and Transformers and Universal Transformers are used for caption generation. We tested our models on MSVD and ActivityNet datasets. Our results show that our models are capable of both single and multi-sentence caption generation without any modification needed. 
